{
  "paragraphs": [
    {
      "text": "%md\n# Introduction to Spark on Zeppelin\nIf you are seeing this then you were able to get your local environment running. Congrats.",
      "user": "anonymous",
      "dateUpdated": "2021-01-17 20:26:26.349",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eIntroduction to Spark on Zeppelin\u003c/h1\u003e\n\u003cp\u003eIf you are seeing this then you were able to get your local environment running. Congrats.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610833094066_1219732012",
      "id": "paragraph_1610833094066_1219732012",
      "dateCreated": "2021-01-16 21:38:14.073",
      "dateStarted": "2021-01-17 20:26:26.351",
      "dateFinished": "2021-01-17 20:26:27.866",
      "status": "FINISHED"
    },
    {
      "text": "%spark\n// shows the spark settings and primes the spark session and context\nspark.sparkContext.getConf.toDebugString",
      "user": "anonymous",
      "dateUpdated": "2021-01-17 20:26:31.596",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610320103402_199331554",
      "id": "paragraph_1610320103402_199331554",
      "dateCreated": "2021-01-10 23:08:23.402",
      "dateStarted": "2021-01-17 20:26:31.613",
      "dateFinished": "2021-01-17 20:26:52.861",
      "status": "FINISHED"
    },
    {
      "text": "%md\n## Read and Analyze\nThis next paragraph shows the most basic of Spark methods for file based reading. The zero-bells attached `spark.read.text`.\nThis is useful technique if you are working data for the first time and don\u0027t know how to parse it, or maybe are having issues using other methods for automatic parsing.\n",
      "user": "anonymous",
      "dateUpdated": "2021-01-17 20:28:05.927",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eRead and Analyze\u003c/h2\u003e\n\u003cp\u003eThis next paragraph shows the most basic of Spark methods for file based reading. The zero-bells attached \u003ccode\u003espark.read.text\u003c/code\u003e.\u003cbr /\u003e\nThis is useful technique if you are working data for the first time and don\u0026rsquo;t know how to parse it, or maybe are having issues using other methods for automatic parsing.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610832378788_1358698633",
      "id": "paragraph_1610832378788_1358698633",
      "dateCreated": "2021-01-16 21:26:18.795",
      "dateStarted": "2021-01-17 20:28:05.928",
      "dateFinished": "2021-01-17 20:28:05.950",
      "status": "FINISHED"
    },
    {
      "title": "Read and Analyze",
      "text": "%spark\n// parse the raw coffee file. this is a simple csv file without headers. The goal is to build core skills: parsing, exploring data\n// format: name, boldness\n\nval df \u003d spark.read.text(\"file:///learn/raw-coffee.txt\")\ndf.printSchema\n",
      "user": "anonymous",
      "dateUpdated": "2021-01-17 20:29:42.865",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- value: string (nullable \u003d true)\n\n\u001b[1m\u001b[34mdf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [value: string]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610320158652_480149",
      "id": "paragraph_1610320158652_480149",
      "dateCreated": "2021-01-10 23:09:18.653",
      "dateStarted": "2021-01-17 20:29:42.884",
      "dateFinished": "2021-01-17 20:29:46.211",
      "status": "FINISHED"
    },
    {
      "text": "%md\n## Exercise: Basic File Reading and Custom Parsing\nFollow along with the exercise in the chapter by adding a new paragraph below. Just hover below this paragraph and *Add Paragraph*. \n\nRemember. The `%spark` denotes that the paragraph is going to run with instructions against the current Spark Session.",
      "user": "anonymous",
      "dateUpdated": "2021-01-17 20:33:33.052",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eExercise: Basic File Reading and Custom Parsing\u003c/h2\u003e\n\u003cp\u003eFollow along with the exercise in the chapter by adding a new paragraph below. Just hover below this paragraph and \u003cem\u003eAdd Paragraph\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eRemember. The \u003ccode\u003e%spark\u003c/code\u003e denotes that the paragraph is going to run with instructions against the current Spark Session.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610915402411_709840804",
      "id": "paragraph_1610915402411_709840804",
      "dateCreated": "2021-01-17 20:30:02.411",
      "dateStarted": "2021-01-17 20:33:33.052",
      "dateFinished": "2021-01-17 20:33:33.076",
      "status": "FINISHED"
    }
  ],
  "name": "IntroToSparkOnZeppelin",
  "id": "2FWJW97H4",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0-preview2",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}